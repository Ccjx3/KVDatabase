# 跳表优化设计方案

## 一、项目背景

本项目是基于跳表实现的轻量级KV存储引擎。原版实现使用全局互斥锁保证线程安全，在高并发场景下存在性能瓶颈。本方案针对并发性能和内存管理进行优化。

## 二、性能瓶颈分析

### 2.1 原版跳表的问题

**问题1：全局锁竞争严重**
```cpp
// 原版实现 - skiplist.h
std::mutex mtx;  // 全局互斥锁

int insert_element(const K key, const V value) {
    mtx.lock();    // 所有操作都竞争同一把锁
    // ... 插入逻辑 ...
    mtx.unlock();
}
```

**影响**：
- 多线程环境下，所有操作串行化
- CPU利用率低，线程大量时间花在等待锁上
- 并发性能无法随线程数增加而提升

**问题2：频繁的内存分配**
```cpp
Node<K, V>* create_node(const K k, const V v, int level) {
    Node<K, V> *n = new Node<K, V>(k, v, level);  // 每次都new
    return n;
}

void delete_element(K key) {
    // ...
    delete current;  // 每次都delete
}
```

**影响**：
- 每次插入/删除都调用系统内存分配器
- 产生大量内存碎片
- 内存分配/释放本身有性能开销
- 高并发下内存分配器成为瓶颈

### 2.2 性能测试数据

**原版跳表性能**（单线程）：
- 插入10万条数据：4.10秒
- 查询10万次：5.43秒
- 写QPS：24.39万
- 读QPS：18.41万

**多线程性能问题**：
- 使用8线程插入，性能反而下降
- 锁竞争导致大量线程阻塞

## 三、优化方案设计

### 3.1 优化方向

本项目采用两个核心优化策略：

1. **细粒度锁优化** - 分段锁机制
2. **内存池优化** - 对象复用机制

### 3.2 细粒度锁优化（分段锁）

#### 设计思路

借鉴Java `ConcurrentHashMap`的分段锁设计，将跳表的键空间划分为多个段（Segment），每个段有独立的锁。

```
键空间划分：
┌─────────────────────────────────────────────┐
│  Segment 0  │  Segment 1  │ ... │ Segment 15 │
│   Lock 0    │   Lock 1    │ ... │   Lock 15  │
└─────────────────────────────────────────────┘

Key 分配：
- key=5  → hash(5) % 16 = 5  → Segment 5
- key=18 → hash(18) % 16 = 2 → Segment 2
- key=23 → hash(23) % 16 = 7 → Segment 7
```

#### 核心优势

**并发度提升**：
- 不同段的操作可以并发执行
- 理论并发度 = 段数量（如16个段支持16个线程同时写）

**锁粒度控制**：
- 只锁定操作涉及的段
- 减少锁持有时间
- 降低锁竞争概率

#### 实现架构

```cpp
// segment_lock.h - 分段锁管理器
template<typename K>
class SegmentLockManager {
private:
    int _segment_count;           // 段数量（默认16）
    std::mutex* _segment_locks;   // 锁数组
    
public:
    // 根据key计算所属段
    int get_segment_index(const K& key) const {
        size_t hash_value = std::hash<K>{}(key);
        return hash_value % _segment_count;
    }
    
    // 获取段的写锁
    std::unique_lock<std::mutex> get_write_lock(int segment_index);
    
    // 获取段的读锁
    std::unique_lock<std::mutex> get_read_lock(int segment_index);
    
    // 获取所有段的锁（用于全局操作）
    std::vector<std::unique_lock<std::mutex>> get_all_write_locks();
};
```

#### 使用示例

```cpp
// 插入操作 - 只锁定key所属的段
int insert_element(const K key, const V value) {
    int segment_index = _lock_manager.get_segment_index(key);
    auto lock = _lock_manager.get_write_lock(segment_index);  // 只锁一个段
    
    // ... 插入逻辑 ...
}

// 并发场景：
// 线程A插入key=5  → 锁Segment 5
// 线程B插入key=18 → 锁Segment 2  ✓ 可以并发执行
// 线程C插入key=23 → 锁Segment 7  ✓ 可以并发执行
```

### 3.3 内存池优化

#### 设计思路

实现对象池模式，预分配节点并复用，避免频繁调用系统内存分配器。

```
内存池工作流程：
┌──────────────────────────────────────┐
│         NodeMemoryPool               │
│                                      │
│  Free List: [Node1, Node2, Node3]   │
│                                      │
│  allocate() → 从Free List取节点      │
│  deallocate() → 归还节点到Free List  │
└──────────────────────────────────────┘

第一次分配：
  allocate() → Free List为空 → new Node → 返回

后续分配：
  allocate() → Free List有节点 → 取出复用 → 返回

节点释放：
  deallocate() → 不delete → 放入Free List → 等待复用
```

#### 核心优势

**性能提升**：
- 减少系统调用次数
- 避免内存分配器的锁竞争
- 提高缓存命中率（复用的内存地址相近）

**内存管理**：
- 减少内存碎片
- 可控的内存使用
- 统一的内存回收

#### 实现架构

```cpp
// memory_pool.h - 节点内存池
template<typename K, typename V>
class NodeMemoryPool {
private:
    std::vector<NodeOpt<K, V>*> _free_list;  // 空闲节点列表
    std::mutex _pool_mutex;                   // 保护内存池
    int _allocated_count;                     // 统计：总分配次数
    int _reused_count;                        // 统计：复用次数
    
public:
    // 分配节点
    NodeOpt<K, V>* allocate(const K& key, const V& value, int level) {
        std::lock_guard<std::mutex> lock(_pool_mutex);
        
        if (!_free_list.empty()) {
            // 从空闲列表取节点复用
            NodeOpt<K, V>* node = _free_list.back();
            _free_list.pop_back();
            reinitialize_node(node, key, value, level);
            _reused_count++;
            return node;
        } else {
            // 空闲列表为空，创建新节点
            _allocated_count++;
            return new NodeOpt<K, V>(key, value, level);
        }
    }
    
    // 回收节点
    void deallocate(NodeOpt<K, V>* node) {
        std::lock_guard<std::mutex> lock(_pool_mutex);
        _free_list.push_back(node);  // 不delete，放入空闲列表
    }
};
```

#### 使用示例

```cpp
// 优化版跳表使用内存池
template <typename K, typename V> 
class SkipListOptimized {
private:
    NodeMemoryPool<K, V> _memory_pool;  // 内存池
    
public:
    NodeOpt<K, V>* create_node(const K k, const V v, int level) {
        return _memory_pool.allocate(k, v, level);  // 从内存池分配
    }
    
    void delete_element(K key) {
        // ...
        _memory_pool.deallocate(current);  // 归还到内存池
    }
};
```

### 3.4 优化版架构图

```
┌─────────────────────────────────────────────────────────┐
│              SkipListOptimized<K, V>                    │
├─────────────────────────────────────────────────────────┤
│  - _header: NodeOpt<K,V>*                               │
│  - _max_level: int                                      │
│  - _element_count: int                                  │
│  - _lock_manager: SegmentLockManager<K>  ← 分段锁       │
│  - _memory_pool: NodeMemoryPool<K,V>     ← 内存池       │
├─────────────────────────────────────────────────────────┤
│  + insert_element(K, V)                                 │
│  + delete_element(K)                                    │
│  + search_element(K)                                    │
│  + display_list()                                       │
└─────────────────────────────────────────────────────────┘
         │                           │
         │                           │
         ▼                           ▼
┌──────────────────┐      ┌──────────────────────┐
│ SegmentLockManager│      │  NodeMemoryPool      │
├──────────────────┤      ├──────────────────────┤
│ - _segment_locks │      │ - _free_list         │
│ - _segment_count │      │ - _pool_mutex        │
├──────────────────┤      ├──────────────────────┤
│ + get_write_lock │      │ + allocate()         │
│ + get_read_lock  │      │ + deallocate()       │
└──────────────────┘      └──────────────────────┘
```

## 四、线程安全设计

### 4.1 锁的层次结构

优化版跳表使用多层锁保护不同的数据：

```cpp
class SkipListOptimized {
private:
    SegmentLockManager<K> _lock_manager;  // 分段锁（保护节点数据）
    std::mutex _level_mutex;              // 保护 _skip_list_level
    std::mutex _count_mutex;              // 保护 _element_count
    std::mutex _global_mutex;             // 保护全局操作（如display）
};
```

### 4.2 锁的获取顺序

为避免死锁，严格按照以下顺序获取锁：

1. `_level_mutex` （层级锁）
2. `_lock_manager` 的段锁
3. `_count_mutex` （计数锁）

### 4.3 读写操作的锁策略

**写操作（insert/delete）**：
```cpp
int insert_element(const K key, const V value) {
    int segment_index = _lock_manager.get_segment_index(key);
    auto lock = _lock_manager.get_write_lock(segment_index);  // 段写锁
    std::lock_guard<std::mutex> level_lock(_level_mutex);     // 层级锁
    
    // ... 插入逻辑 ...
    
    {
        std::lock_guard<std::mutex> count_lock(_count_mutex); // 计数锁
        _element_count++;
    }
}
```

**读操作（search）**：
```cpp
bool search_element(K key) {
    int segment_index = _lock_manager.get_segment_index(key);
    auto lock = _lock_manager.get_read_lock(segment_index);   // 段读锁
    
    int current_level;
    {
        std::lock_guard<std::mutex> level_lock(_level_mutex); // 快速读取层级
        current_level = _skip_list_level;
    }
    
    // ... 查找逻辑 ...
}
```

**全局操作（display/dump）**：
```cpp
void display_list() {
    std::lock_guard<std::mutex> lock(_global_mutex);
    auto locks = _lock_manager.get_all_write_locks();  // 获取所有段的锁
    
    // ... 显示逻辑 ...
}
```

## 五、预期性能提升

### 5.1 理论分析

**分段锁优化**：
- 并发度：从1提升到16（16个段）
- 锁竞争：降低约93.75%（1/16）
- 多线程扩展性：接近线性扩展

**内存池优化**：
- 内存分配次数：减少50%-80%（取决于复用率）
- 系统调用开销：大幅降低
- 缓存命中率：提升

### 5.2 性能目标

**单线程性能**：
- 插入QPS：25万+ （与原版持平或略优）
- 查询QPS：20万+ （与原版持平或略优）

**多线程性能**（8线程）：
- 插入QPS：100万+ （原版的4-5倍）
- 查询QPS：150万+ （原版的8-10倍）
- 内存复用率：60%+

## 六、实现要点

### 6.1 关键技术点

1. **哈希函数选择**：使用`std::hash`保证key均匀分布到各段
2. **锁粒度平衡**：16个段是经验值，可根据CPU核心数调整
3. **内存池大小**：初始容量100，可根据实际负载调整
4. **RAII原则**：使用`std::lock_guard`和`std::unique_lock`自动管理锁

### 6.2 注意事项

1. **死锁预防**：严格按顺序获取多个锁
2. **异常安全**：使用RAII保证异常时锁能正确释放
3. **内存泄漏**：内存池析构时需释放所有缓存节点
4. **统计信息**：提供内存池统计接口，便于性能分析

## 七、测试验证

### 7.1 功能测试

- 基本操作：插入、删除、查询、显示
- 边界条件：空跳表、单元素、大量元素
- 并发正确性：多线程同时读写

### 7.2 性能测试

- 单线程性能：与原版对比
- 多线程性能：2/4/8/16线程扩展性
- 内存使用：内存池复用率统计

### 7.3 压力测试

- 长时间运行稳定性
- 大数据量测试（百万级）
- 混合读写场景

## 八、总结

本优化方案通过**分段锁**和**内存池**两个核心技术，在保证线程安全的前提下，显著提升了跳表的并发性能和内存管理效率。

**核心创新点**：
1. 借鉴ConcurrentHashMap的分段锁设计
2. 实现对象池模式减少内存分配开销
3. 多层次锁保护不同粒度的数据
4. 提供详细的性能统计接口

**适用场景**：
- 高并发读写场景
- 多核CPU环境
- 对延迟敏感的应用
- 需要高QPS的KV存储

**扩展方向**：
- 读写锁优化（`std::shared_mutex`）
- 无锁数据结构（lock-free）
- 自适应分段数量
- 内存池预热机制
